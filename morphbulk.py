#!/usr/bin/python3.5
"""
Arthur Zwaenepoel
MORPH bulk command line interface (CLI)
"""

import click
import os
import coloredlogs, logging
import sys
from morph_bulk.add_species import format_groups, write_config, check_directory, write_jobs, MorphConfig
from morph_bulk.morph_chunked import morph_chunked_run
from morph_bulk.random_baits import random_bulk_run
from morph_bulk.morph_bulk_post import summary
from morph_bulk.pre_process import filter_matrix, normalize_matrix, cluster_matrix
from morph_bulk.morph_bulk_to_rdf import morph_to_rdf


# CLI ------------------------------------------------------------------------------------------------------------------
@click.group()
@click.option('--verbose', type=click.Choice(['silent', 'info', 'debug']),
              default='info', help="Verbosity level, default = info.")
def cli(verbose):
    """
    Welcome to the MORPH bulk run command line interface!

    \b
                                 _     _           _ _
                                | |   | |         | | |
      _ __ ___   ___  _ __ _ __ | |__ | |__  _   _| | | __
     | '_ ` _ \\ / _ \\| '__| '_ \\| '_ \\| '_ \\| | | | | |/ /
     | | | | | | (_) | |  | |_) | | | | |_) | |_| | |   <
     |_| |_| |_|\\___/|_|  | .__/|_| |_|_.__/ \\__,_|_|_|\\_\\
                          | |
                          |_|
        \b
    """
    if verbose == 'debug':
        coloredlogs.install()
        logging.basicConfig(format='%(asctime)s: %(levelname)s\t%(message)s', level=logging.DEBUG,
                            stream=sys.stdout)

    elif verbose == 'info':
        coloredlogs.install()
        logging.basicConfig(format='%(asctime)s: %(levelname)s\t%(message)s', level=logging.INFO,
                            stream=sys.stdout)

    pass


# PIPELINE -------------------------------------------------------------------------------------------------------------
@cli.command(context_settings={'help_option_names': ['-h', '--help']})
@click.argument('base_path', type=click.Path(exists=True))
@click.argument('species')
@click.argument('functional_annotation')
@click.argument('morph_path')
@click.argument('output_directory')
@click.option('--cache_path','-c', default='./tmp/cache',
              help="Path to caching directory for MORPH, default = ./tmp/cache")
@click.option('--gene_sets_type','-t', default='go',
              help="Type of gene sets you provide (functional annotation) (default = 'go').")
@click.option('--chunk_size','-cs', default=100,
              help="Chunk size for MORPH bulk run, default = 100.")
@click.option('--number_of_candidates','-n', default=100,
              help="Number of candidates in MORPH output for a gene set, default = 30.")
@click.option('--p_values','-p', default=None,
              help="File with p-values, as generated by random_baits.py")
@click.option('--random_run/--no_random', default=False,
              help='Perform random runs?')
@click.option('--range_start','-r1', default=5,
              help='Number of genes per random set to start with')
@click.option('--range_end','-r2', default=35,
              help='Highest number of genes per random set')
@click.option('--number_total','-n', default=1000,
              help='Total number of random sets per gene number to evaluate')
@click.option('--p_val_cut_off', '-d', default=0.05,
              help="p-value cut-off for extended annotation (default=0.05)")
@click.option('--score_cut_off', '-s', default=1.65,
              help="z-score cut off for extended annotation (default=1.65)")
@click.option('--set_descriptions', '-sd', default='go',
              help="Tab delimietd file with bait set descriptions, if not provided godb annotation is used.")
def pipeline(base_path, species, functional_annotation, output_directory,
             morph_path, cache_path, gene_sets_type, chunk_size, number_of_candidates,
             p_values, random_run, range_start, range_end, number_total, p_val_cut_off, score_cut_off, set_descriptions):
    """
    MORPH bulk run pipeline.

    Python command line utility for performing MORPH bulk analysis in a pipeline fashion.

    \b
    Requires as input:
    - Base path (path to dir with config file, data sets and clusterings). Should have the following structure.
        base_path/
            ./datasets
                ./dataset1
                ./dataset2
            ./clusterings
                ./click
                    ./dataset1.click.clustering
                    ./dataset2.click.clustering
                ./ppi
                    ./dataset1.ppi.clustering
                    ./dataset2.ppi.clustering
            ./gene_descriptions.tsv

    - Species name
    - Functional annotation (tab delimited file with gene to functional term mapping)
    - Path to MORPH executable (tested with MORPH C++ v1.0.6)
    - Output directory
    """
    config = MorphConfig(base_path, species, functional_annotation,
                         output_directory, morph_path, cache_path, gene_sets_type)

    # 1. Pre-processing
    logging.info("Started pre-processing")
    check_directory(config)

    logging.info("Writing configuration file")
    config.config_file = write_config(config)

    logging.info("Writing jobs")
    format_groups(config)
    config.jobs = write_jobs(config)

    # 2. MORPH run (chunked)
    logging.info("Running Morph")
    morph_chunked_run(config.config_file, config.jobs, config.bulk_out,
                      chunk_size, number_of_candidates, config.morph)

    # 3. Random run
    if random_run:
        logging.info("Performing random run")
        p_values = random_bulk_run(config.config_file, config.data_sets,
                                   os.path.join(config.output_dir, 'rr.csv'),
                                   config.morph, range_start, range_end, number_total, chunk_size)

    if p_values:
        logging.info("Found precomputed p-values")

        logging.info("Generating summary, extended annotation and supplementary tables")
        if set_descriptions == 'go':
            go = True
            set_descriptions = False
        else:
            go = False

        summary(config.bulk_out, os.path.join(config.output_dir, 'summary'), p_values, set_descriptions, go,
                supplementary=True, p_val_cut_off=p_val_cut_off, score_cut_off=score_cut_off, full=False)

        logging.info("Done!")

    else:
        logging.info("No random run performed, no precomputed p-values provided")
        logging.info("Done!")


# ADD ------------------------------------------------------------------------------------------------------------------
@cli.command(context_settings={'help_option_names': ['-h', '--help']})
@click.argument('base_path', type=click.Path(exists=True))
@click.argument('species')
@click.option('--functional_annotation','-a', default=None,
              help="Functional annotation file")
@click.option('--gene_sets','-s', default=None,
              help="Gene set file (rows: GO_ID [TAB] gene1, gene2.)")
@click.option('--gene_sets_type','-t', default='go',
              help="What type of gene sets you provide (e.g. GO, mapman, ...).")
@click.option('--plaza/--no_plaza', default=True,
              help="PLAZA style csv? Or TAB separated gene TAB GO? (Default: PLAZA)")
@click.option('--cache_path','-c', default='./tmp/cache',
              help="Path to caching directory for MORPH, default = ./tmp/cache")
def add(base_path, species, functional_annotation, gene_sets, gene_sets_type, plaza, cache_path):
    """
    Add a species to Morph.

    Writes a morph config file (yaml format).
    and jobs for bulk run if gene sets are provided.

    INPUT:
        - BASE_PATH: the full absolute path to the directory with data
        - SPECIES: a species name/ID (without spaces)

    The directory should have following structure :

    \b
    base_path/
        ./datasets
            ./dataset1
            ./dataset2
        ./clusterings
            ./click
                ./dataset1.click.clustering
                ./dataset2.click.clustering
            ./ppi
                ./dataset1.ppi.clustering
                ./dataset2.ppi.clustering
        ./gene_descriptions.tsv
    \b

    Works with Morph v1.0.6
    """
    morph_config = MorphConfig(base_path, species, gene_sets, cache_path, gene_sets_type)

    logging.info("Checking directory structure ...")
    check_directory(morph_config)
    if functional_annotation is not None and gene_sets is not None:
        raise AssertionError("Both functional annotation and gene sets provided, please provide only one.")

    logging.info("Writing configuration file for Morph v1.0.6 ...")
    write_config(morph_config)

    if functional_annotation:
        logging.info("Processing functional annotation ...")
        morph_config.gene_sets = functional_annotation
        format_groups(morph_config, plaza)
        logging.info("Writing joblist ...")
        write_jobs(morph_config)

    elif gene_sets:
        logging.info("Processing gene sets ...")
        morph_config.gene_sets = gene_sets
        logging.info("Writing joblist ...")
        write_jobs(morph_config)


# RANDOM ---------------------------------------------------------------------------------------------------------------
@cli.command(context_settings={'help_option_names': ['-h', '--help']})
@click.argument('morph_config_file', type=click.Path(exists=True))
@click.argument('data_sets_dir', type=click.Path(exists=True))
@click.argument('output_file', type=click.Path(exists=False))
@click.option('--morph_path','-m', default='morph',
              help='Path to MORPH CLI.')
@click.option('--range_start','-r1', default=5,
              help='Number of genes per random set to start with, DEFAULT=5')
@click.option('--range_end','-r2', default=35,
              help='Highest number of genes per random set, DEFAULT=35')
@click.option('--number_total','-nt', default=1000,
              help='Total number of random sets per gene number to evaluate, DEFAULT=1000')
@click.option('--chunk_size','-n', default=100,
              help='Chunk size for bulk run, DEFAULT=100')
@click.option('--background_set','-b', default=None,
              help='Background set of genes from which to pick random bait sets (OPTIONAL: DEFAULT=genome wide).')
def random(morph_config_file, data_sets_dir, output_file, morph_path, range_start,
           range_end, number_total, chunk_size, background_set):
    """
    Random MORPH bulk run.

    Perform MORPH on n random sets of genes in a defined range [r1,r2]
    """
    random_bulk_run(morph_config_file, data_sets_dir, output_file, morph_path, range_start,
                    range_end, number_total, chunk_size, background_set)


# MORPH ----------------------------------------------------------------------------------------------------------------
@cli.command(context_settings={'help_option_names': ['-h', '--help']})
@click.argument('morph_config_file', type=click.Path(exists=True))
@click.argument('jobs_dir', type=click.Path(exists=True))
@click.argument('output_dir', type=click.Path(exists=False))
@click.option('--chunk_size','-s', default=100, help='Chunk size (default=100).')
@click.option('--number_of_candidates','-n', default=30, help='Number of candidates to output (default=30).')
@click.option('--morph_path','-m', default='morph',
              help='Path to MORPH CLI.')
def morph(morph_config_file, jobs_dir, output_dir, chunk_size, number_of_candidates, morph_path):
    """
    Run MORPH in bulk (chunked).

    Command line utility to run MORPH in chunks.
    Running a bulk MORPH on a full for GO annotation for example uses a lot of memory.
    Chunk sizes of 100 gene sets are used by default.
    Uses UNIX commands.
    """
    # Check directories and files
    morph_chunked_run(morph_config_file, jobs_dir, output_dir, chunk_size, number_of_candidates, morph_path)


# POST -----------------------------------------------------------------------------------------------------------------
@cli.command(context_settings={'help_option_names': ['-h', '--help']})
@click.argument('input_dir', type=click.Path(exists=True))
@click.argument('output_dir', type=click.Path(exists=False))
@click.option('--p_values','-p', type=click.Path(exists=True), default=None,
              help=('CSV file with p-value calculations from random run.'
                    'See random_baits.py for more information.'))
@click.option('--set_descriptions','-s', default=None,
              help='Tab separated file with gene set descriptions (e.g. MapMan pathways) (default=None).')
@click.option('--gene_descriptions','-g', default=None,
              help='Tab separated file with gene descriptions (default=None).')
@click.option('--fdr_level','-fdr', default=0.05,
              help='FDR level to control. (default=0.05)')
@click.option('--score_cut_off','-sc', default=1.96,
              help='Score cut off for including candidates. (default=None)')
@click.option('--full/--not_full', default=False,
              help='Give full results for supplementary (default=False).')
@click.option('--go/--no_go', default=False,
              help='Include GO info from godb (default=False).')
@click.option('--supplementary/--no_supplementary', default=True,
              help='Output supplementary tables with TFs, kinases, unknowns, '
                   'hypotheticals and transporters (default=True).')
def post(input_dir, output_dir, p_values, set_descriptions, gene_descriptions,
         go, supplementary, fdr_level, score_cut_off, full):
    """
    Post-process MORPH bulk results.

    Command line utility for post-processing a MORPH bulk run.
    Particularly useful for getting some statistics of a bulk run.

    OUTPUT:\n
        - summary.csv\n
        - supplementary tables:\n
            - tf.csv\n
            - signal.csv\n
            - transporter.csv\n
            - unknown.csv\n
    """
    if p_values is None:
        raise ValueError("No data to estimate p-values provided (see random_baits.py).")

    if set_descriptions is not None and go:
        raise ValueError("Both gene set descriptions were given and the go flag was set. Please choose one of the two.")

    if fdr_level < 0 or fdr_level > 1:
        raise ValueError("No meaningful p-value cut off {0}".format(fdr_level))

    summary(input_dir, output_dir, p_values, set_descriptions, gene_descriptions,
            go, supplementary, fdr_level, score_cut_off, full)


# RDF ------------------------------------------------------------------------------------------------------------------
@cli.command(context_settings={'help_option_names': ['-h', '--help']})
@click.argument('input_dir', type=click.Path(exists=True))
@click.argument('output_file', type=click.Path(exists=False))
@click.option('--p-values','-p', default=None,
              help='Raw output file of random run. For calculation of p-values.')
@click.option('--gene_descriptions','-g', default=None,
              help='Tab delimited file with gene descriptions. OPTIONAL (by default descriptions '
                   'will be fetched from MORPH results).')
@click.option('--bait_descriptions','-b', default=None,
              help='Tab delimited file with bait group descriptions (GO, PWs, ...).')
@click.option('--gene_families','-f', default=None,
              help='CSV file with gene families (e.g. from PLAZA) (OPTIONAL).')
@click.option('--bait_type','-t', default=None,
              help='Bait set type (e.g. go, mapman).')
@click.option('--species','-s', default=None,
              help='Species name identifier (e.g. ath).')
@click.option('--p_val_cut_off','-pc', default=0.1,
              help='p-value cut off for including gene sets. (DEFAULT=0.1)')
@click.option('--score_cut_off','-c', default=1.282,
              help='Score cut off for including candidates. (DEFAULT=1.282)')
@click.option('--max_candidates','-m', default=100,
              help='Maximum number of candidates to include. (DEFAULT=100)')
def rdf(input_dir, output_file, p_values, gene_descriptions, bait_descriptions,
         gene_families, bait_type, species, p_val_cut_off, score_cut_off, max_candidates):
    """
    Generate RDF graph (for MorphDB).

    Command line tool to generate RDF graph from MORPH bulk run results (MORPH 1.0.6).
    RDF graph can be used to load in a Graph database server (e.g. Allegrograph, Jena Fuseki)
    or a static triple store (e.g. jena TDB). An RDF graph can be efficiently queried using SPARQL.

    INPUT:

        - input_dir: directory with MORPH bulk run results

        - output_file: name of the output file

    OUTPUT:

        - output_file: RDF graph in turtle (.ttl) format
    """
    morph_to_rdf(input_dir, output_file, p_values, gene_descriptions, bait_descriptions,
                 gene_families, bait_type, species, p_val_cut_off, score_cut_off, max_candidates)


if __name__ == '__main__':
    cli()